{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Glasses Reconstruction Pipeline\n",
    "\n",
    "This notebook demonstrates the complete workflow for reconstructing 3D glasses models from 2D images using the Hunyuan3D-2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import trimesh\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.data import GlassesDataset, get_transforms\n",
    "from src.models import HunyuanAdapter, GlassesReconstruction\n",
    "from src.metrics import chamfer_distance, earth_movers_distance, iou_3d\n",
    "from src.utils import visualize_mesh, visualize_point_cloud, visualize_comparison, save_mesh\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set data directory\n",
    "data_dir = '../data'\n",
    "\n",
    "# Create data transforms\n",
    "transforms = get_transforms(image_size=256, split='test')\n",
    "\n",
    "# Create dataset\n",
    "dataset = GlassesDataset(\n",
    "    data_dir=data_dir,\n",
    "    split='test',\n",
    "    transform=transforms['image'],\n",
    "    target_transform=transforms['model'],\n",
    "    image_size=256,\n",
    "    max_samples=10  # Limit to 10 samples for demonstration\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize a few sample images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "for i in range(5):\n",
    "    if i < len(dataset):\n",
    "        sample = dataset[i]\n",
    "        image = sample['image']\n",
    "        \n",
    "        # Convert tensor to numpy array for visualization\n",
    "        image_np = image.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # Denormalize image\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image_np = image_np * std + mean\n",
    "        image_np = np.clip(image_np, 0, 1)\n",
    "        \n",
    "        # Display image\n",
    "        axes[i].imshow(image_np)\n",
    "        axes[i].set_title(f\"Sample {i+1}\")\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create the model\n",
    "base_model = HunyuanAdapter(model_path='tencent/Hunyuan3D-2', device=device)\n",
    "model = GlassesReconstruction(\n",
    "    base_model=base_model,\n",
    "    num_classes=10,\n",
    "    feature_dim=512\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Load checkpoint if available\n",
    "checkpoint_path = '../checkpoints/best_model.pth'\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "else:\n",
    "    print(\"No checkpoint found, using untrained model\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate 3D Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create results directory\n",
    "results_dir = '../results/notebook'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Generate 3D reconstructions for a few samples\n",
    "num_samples = min(5, len(dataset))\n",
    "reconstructions = []\n",
    "\n",
    "for i in tqdm(range(num_samples), desc=\"Generating reconstructions\"):\n",
    "    sample = dataset[i]\n",
    "    image = sample['image'].unsqueeze(0).to(device)  # Add batch dimension\n",
    "    \n",
    "    # Generate mesh\n",
    "    with torch.no_grad():\n",
    "        mesh = model.generate_mesh(\n",
    "            image=image,\n",
    "            with_texture=True,\n",
    "            output_path=os.path.join(results_dir, f\"sample_{i+1}.obj\")\n",
    "        )\n",
    "    \n",
    "    reconstructions.append(mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the reconstructions\n",
    "for i, mesh in enumerate(reconstructions):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    visualize_mesh(mesh, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate reconstructions against ground truth if available\n",
    "metrics = {\n",
    "    'chamfer_distance': [],\n",
    "    'earth_movers_distance': [],\n",
    "    'iou_3d': []\n",
    "}\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample = dataset[i]\n",
    "    gt_mesh_path = sample['model_path']\n",
    "    \n",
    "    if gt_mesh_path is not None and os.path.exists(gt_mesh_path):\n",
    "        # Load ground truth mesh\n",
    "        gt_mesh = trimesh.load(gt_mesh_path)\n",
    "        \n",
    "        # Get predicted mesh\n",
    "        pred_mesh = reconstructions[i]\n",
    "        \n",
    "        # Compute Chamfer distance\n",
    "        cd = chamfer_distance(\n",
    "            pred_mesh.vertices,\n",
    "            gt_mesh.vertices,\n",
    "            bidirectional=True,\n",
    "            reduction='mean'\n",
    "        )\n",
    "        metrics['chamfer_distance'].append(float(cd))\n",
    "        \n",
    "        # Compute Earth Mover's Distance\n",
    "        emd = earth_movers_distance(\n",
    "            pred_mesh.vertices,\n",
    "            gt_mesh.vertices,\n",
    "            reduction='mean'\n",
    "        )\n",
    "        metrics['earth_movers_distance'].append(float(emd))\n",
    "        \n",
    "        # Compute IoU\n",
    "        iou = iou_3d(pred_mesh, gt_mesh)\n",
    "        metrics['iou_3d'].append(float(iou))\n",
    "        \n",
    "        # Visualize comparison\n",
    "        print(f\"Sample {i+1}:\")\n",
    "        visualize_comparison(\n",
    "            meshes=[pred_mesh, gt_mesh],\n",
    "            titles=[\"Predicted\", \"Ground Truth\"],\n",
    "            figsize=(15, 5)\n",
    "        )\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Chamfer Distance: {cd:.4f}\")\n",
    "        print(f\"Earth Mover's Distance: {emd:.4f}\")\n",
    "        print(f\"IoU: {iou:.4f}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compute Average Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute average metrics\n",
    "avg_metrics = {\n",
    "    'chamfer_distance': np.mean(metrics['chamfer_distance']) if metrics['chamfer_distance'] else float('nan'),\n",
    "    'earth_movers_distance': np.mean(metrics['earth_movers_distance']) if metrics['earth_movers_distance'] else float('nan'),\n",
    "    'iou_3d': np.mean(metrics['iou_3d']) if metrics['iou_3d'] else float('nan')\n",
    "}\n",
    "\n",
    "print(\"Average Metrics:\")\n",
    "print(f\"Chamfer Distance: {avg_metrics['chamfer_distance']:.4f}\")\n",
    "print(f\"Earth Mover's Distance: {avg_metrics['earth_movers_distance']:.4f}\")\n",
    "print(f\"IoU: {avg_metrics['iou_3d']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Custom Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to reconstruct a custom image\n",
    "def reconstruct_custom_image(image_path, output_path=None):\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = get_transforms(image_size=256, split='test')['image']\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate mesh\n",
    "    with torch.no_grad():\n",
    "        mesh = model.generate_mesh(\n",
    "            image=image_tensor,\n",
    "            with_texture=True,\n",
    "            output_path=output_path\n",
    "        )\n",
    "    \n",
    "    # Display original image\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize mesh\n",
    "    visualize_mesh(mesh, figsize=(8, 8))\n",
    "    \n",
    "    return mesh\n",
    "\n",
    "# Example usage (uncomment and provide a path to your custom image)\n",
    "# custom_image_path = \"path/to/your/image.jpg\"\n",
    "# custom_output_path = os.path.join(results_dir, \"custom_reconstruction.obj\")\n",
    "# custom_mesh = reconstruct_custom_image(custom_image_path, custom_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook demonstrated the complete workflow for reconstructing 3D glasses models from 2D images using the Hunyuan3D-2 model. The pipeline includes:\n",
    "\n",
    "1. Loading and preprocessing the dataset\n",
    "2. Loading the model\n",
    "3. Generating 3D reconstructions\n",
    "4. Visualizing the reconstructions\n",
    "5. Evaluating the reconstructions using various metrics\n",
    "6. Reconstructing custom images\n",
    "\n",
    "The model can be further improved by training on a larger dataset of glasses images and their corresponding 3D models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
